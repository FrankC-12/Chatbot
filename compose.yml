version: '3.8'

services:
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile  # Asegúrate de que este es el nombre de tu Dockerfile
    ports:
      - "10000:10000"  # Mapea el puerto 10000 del contenedor al 10000 de tu máquina
    environment:
      - OLLAMA_API_URL=http://ollama:8080  # URL de la API de Ollama, ajusta según sea necesario
    volumes:
      - .:/app  # Monta el directorio actual en /app dentro del contenedor

  ollama:
    image: ollama/ollama  # Usa la imagen oficial de Ollama 3.1
    ports:
      - "8080:8080"  # Mapea el puerto 8080 del contenedor al 8080 de tu máquina
    restart: always  # Reinicia el contenedor automáticamente si falla
    environment:
      # Puedes agregar aquí cualquier variable de entorno que Ollama requiera
      - MODEL_NAME=your_model_name  # Especifica el nombre del modelo que quieres usar
